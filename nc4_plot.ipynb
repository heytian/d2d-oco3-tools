{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN188p51WqzAiplFtY0fj2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heytian/d2d-oco3-tools/blob/main/nc4_plot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from ipywidgets import interact, IntSlider, SelectMultiple\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Base folder containing .nc4 files (replace with your own google drive shortcut to D2D shared drive)\n",
        "DATA_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/2022-CO2-netcdfs\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Discover years and files\n",
        "files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".nc4\")]\n",
        "years = sorted(list({f.split('_')[2][:2] for f in files}))  # extract '24' from '240716'\n",
        "print(f\"Found {len(files)} total NC4 files.\")\n"
      ],
      "metadata": {
        "id": "br2lxwKiC7Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample files per year\n",
        "files_by_year = {}\n",
        "for f in files:\n",
        "    year = \"20\" + f.split('_')[2][:2]\n",
        "    files_by_year.setdefault(year, []).append(f)\n",
        "\n",
        "available_years = sorted(files_by_year.keys())\n",
        "print(\"Available years:\", available_years)\n",
        "\n",
        "# Let user choose interactively\n",
        "@interact(\n",
        "    year=available_years,\n",
        "    n_files=IntSlider(min=1, max=10, step=1, value=3, description='Files to process'),\n",
        ")\n",
        "def choose_year(year, n_files):\n",
        "    chosen = files_by_year[year][:n_files]\n",
        "    print(f\"Will process {len(chosen)} files from {year}:\")\n",
        "    for f in chosen:\n",
        "        print(\" -\", f)\n",
        "    globals()['SELECTED_FILES'] = chosen\n"
      ],
      "metadata": {
        "id": "if7Ul_mAGUyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recursively collect dataset paths in an HDF5 file\n",
        "def collect_datasets(h5file):\n",
        "    dataset_paths = []\n",
        "\n",
        "    def visitor(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset):\n",
        "            dataset_paths.append(name)\n",
        "    h5file.visititems(visitor)\n",
        "    return dataset_paths\n",
        "\n",
        "# First, pick a sample file to list variables\n",
        "sample_file = os.path.join(DATA_DIR, SELECTED_FILES[0]) # test 1 file\n",
        "# sample_file = os.path.join(DATA_DIR, files[0]) # all files\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "    all_datasets = collect_datasets(f)\n",
        "\n",
        "# Let user select variables interactively\n",
        "\n",
        "preselected_vars = [\n",
        "    'sounding_id',\n",
        "    'Sounding/operation_mode',\n",
        "    'xco2',\n",
        "    'xco2_quality_flag',\n",
        "    'latitude',\n",
        "    'longitude',\n",
        "    'Sounding/target_name'\n",
        "]\n",
        "\n",
        "@interact(\n",
        "    variables=SelectMultiple(\n",
        "        options=all_datasets,\n",
        "        value=[v for v in preselected_vars if v in all_datasets],\n",
        "        description='Variables',\n",
        "        layout={'width': 'max-content'},\n",
        "        rows=15\n",
        "    )\n",
        ")\n",
        "def choose_variables(variables):\n",
        "    print(\"Selected variables for CSV extraction:\")\n",
        "    for v in variables:\n",
        "        print(\" -\", v)\n",
        "    globals()['SELECTED_VARS'] = variables\n"
      ],
      "metadata": {
        "id": "y5XS1DN-jUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get time from sounding_id and filter functions for good quality SAMs\n",
        "\n",
        "def filter_and_extract_time(df):\n",
        "    \"\"\"\n",
        "    Filter the DataFrame for SAM/AM mode and good quality, and extract datetime from sounding_id.\n",
        "    \"\"\"\n",
        "    # Ensure sounding_id is string\n",
        "    df['sounding_id'] = df['sounding_id'].astype(str)\n",
        "\n",
        "    # Extract datetime from sounding_id (YYYYMMDDHHMM)\n",
        "    df['year'] = df['sounding_id'].str[:4].astype(int)\n",
        "    df['month'] = df['sounding_id'].str[4:6].astype(int)\n",
        "    df['day'] = df['sounding_id'].str[6:8].astype(int)\n",
        "    df['hour'] = df['sounding_id'].str[8:10].astype(int)\n",
        "    df['minute'] = df['sounding_id'].str[10:12].astype(int)\n",
        "    df['datetime'] = pd.to_datetime(df[['year','month','day','hour','minute']])\n",
        "\n",
        "    # Filter for SAM (AM) only\n",
        "    df = df[df['sounding_operation_mode'] == 'AM']\n",
        "\n",
        "    # Filter for good quality flag\n",
        "    df = df[df['xco2_quality_flag'] == 0]\n",
        "\n",
        "    # Drop intermediate columns\n",
        "    df = df.drop(columns=['year','month','day','hour','minute'])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Rm4K2Kh1ss4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV file extraction\n",
        "\n",
        "def process_nc4_file(local_path, variables): # all files\n",
        "    filename = os.path.basename(local_path)\n",
        "    csv_name = os.path.join(OUTPUT_DIR, filename.replace(\".nc4\", \".csv\"))\n",
        "\n",
        "    try:\n",
        "        with h5py.File(local_path, 'r') as f:\n",
        "            out_dict = {}\n",
        "            for var in variables:\n",
        "                # Direct access\n",
        "                if var in f:\n",
        "                    out_dict[var.replace('/', '_')] = f[var][...]\n",
        "                else:\n",
        "                    # Search for nested dataset ending with last component of var\n",
        "                    var_name = var.split('/')[-1]\n",
        "                    found = False\n",
        "                    def find_dataset(name, obj):\n",
        "                        nonlocal found\n",
        "                        if isinstance(obj, h5py.Dataset) and name.endswith(var_name):\n",
        "                            out_dict[name.replace('/', '_')] = obj[...]\n",
        "                            found = True\n",
        "                    f.visititems(find_dataset)\n",
        "                    if not found:\n",
        "                        print(f\"Warning: variable {var} not found in {filename}\")\n",
        "\n",
        "            # Map Sounding/operation_mode integers to strings if present\n",
        "            key_opmode = [k for k in out_dict.keys() if k.endswith('operation_mode')]\n",
        "            if key_opmode:\n",
        "                k = key_opmode[0]\n",
        "                mapping = {0: 'ND', 1: 'GL', 2: 'TG', 3: 'XS', 4: 'AM'}\n",
        "                out_dict[k] = [mapping.get(int(v), 'UNK') for v in out_dict[k]]\n",
        "\n",
        "            df = pd.DataFrame(out_dict)\n",
        "\n",
        "            # Filter for SAM mode (AM) and good quality, and extract datetime\n",
        "            if 'sounding_operation_mode' in df.columns and 'xco2_quality_flag' in df.columns:\n",
        "                df = df[(df['sounding_operation_mode'] == 'AM') & (df['xco2_quality_flag'] == 0)]\n",
        "            if 'sounding_id' in df.columns:\n",
        "                df['datetime'] = df['sounding_id'].astype(str).apply(\n",
        "                    lambda x: f\"20{x[:2]}-{x[2:4]}-{x[4:6]} {x[8:10]}:{x[10:12]}:00\"\n",
        "                )\n",
        "\n",
        "            df.to_csv(csv_name, index=False)\n",
        "            print(f\"Saved CSV: {csv_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed {local_path}: {e}\")\n"
      ],
      "metadata": {
        "id": "nQeUnj3VGiV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all():\n",
        "    for f in tqdm(SELECTED_FILES, desc=f\"Processing {len(SELECTED_FILES)} files\"):\n",
        "        local_path = os.path.join(DATA_DIR, f)\n",
        "        process_nc4_file(local_path, SELECTED_VARS)\n",
        "\n",
        "run_all()\n"
      ],
      "metadata": {
        "id": "1yXO9MT6Hky_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}