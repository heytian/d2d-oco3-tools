{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNA9aYZSRWBNHn1/ldkcLlU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heytian/d2d-oco3-tools/blob/main/nc4_plot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. NC4 Files to CSV**\n",
        "\n",
        "This is a tool to filter for high quality SAMs, and to aggregate a single CO2 value for each SAM location (taking the median CO2), from a folder of multiple nc4s. The lat/lon is the center point of all the soundings with the same target_name."
      ],
      "metadata": {
        "id": "SZVFcUK43QIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from ipywidgets import interact, IntSlider\n",
        "\n",
        "# -----------------------------\n",
        "# PATHS\n",
        "# -----------------------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/2024-CO2-netcdfs\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Discover NC4 files\n",
        "files = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.nc4')])\n",
        "print(f\"Found {len(files)} NC4 files.\")\n",
        "\n",
        "# -----------------------------\n",
        "# INTERACTIVE FILE SELECTION\n",
        "# -----------------------------\n",
        "@interact(n_files=IntSlider(min=1, max=len(files), step=1, value=3, description='Files to process'))\n",
        "def select_files(n_files):\n",
        "    global SELECTED_FILES\n",
        "    SELECTED_FILES = files[:n_files]\n",
        "    print(f\"Selected {len(SELECTED_FILES)} files:\")\n",
        "    for f in SELECTED_FILES:\n",
        "        print(\" -\", f)\n",
        "\n",
        "# -----------------------------\n",
        "# READ AND FILTER ONE FILE\n",
        "# -----------------------------\n",
        "def read_filter_file(path):\n",
        "    with h5py.File(path, 'r') as f:\n",
        "        ns = len(f['sounding_id'])\n",
        "        data = np.zeros(ns, dtype=[('sounding_id','int64'),\n",
        "                                   ('xco2','f8'),\n",
        "                                   ('operation_mode','S2'),\n",
        "                                   ('xco2_quality_flag','i1'),\n",
        "                                   ('target_name','S100'),\n",
        "                                   ('latitude','f8'),\n",
        "                                   ('longitude','f8')])\n",
        "        # Direct extraction\n",
        "        data['sounding_id'] = f['sounding_id'][...]\n",
        "        data['xco2'] = f['xco2'][...]\n",
        "        op = f['Sounding/operation_mode'][...]\n",
        "        mapping = {0:b'ND',1:b'GL',2:b'TG',3:b'XS',4:b'AM'}\n",
        "        data['operation_mode'] = np.array([mapping.get(int(v), b'UNK') for v in op])\n",
        "        data['xco2_quality_flag'] = f['xco2_quality_flag'][...]\n",
        "        data['target_name'] = f['Sounding/target_name'][...]\n",
        "        data['latitude'] = f['latitude'][...]\n",
        "        data['longitude'] = f['longitude'][...]\n",
        "\n",
        "    # Filter: AM + quality_flag 0\n",
        "    mask = (data['operation_mode'] == b'AM') & (data['xco2_quality_flag'] == 0)\n",
        "    data = data[mask]\n",
        "\n",
        "    # Add datetime (optional, per sounding)\n",
        "    dt_strings = np.array([str(s)[:14] for s in data['sounding_id']])\n",
        "    data = np.lib.recfunctions.append_fields(data, 'datetime',\n",
        "                                             pd.to_datetime(dt_strings, format='%Y%m%d%H%M%S'),\n",
        "                                             usemask=False)\n",
        "    return data\n",
        "\n",
        "# -----------------------------\n",
        "# COMBINE FILES INTO ONE CSV\n",
        "# -----------------------------\n",
        "def combine_files(output_csv=\"combined_median.csv\"):\n",
        "    import numpy.lib.recfunctions as rfn\n",
        "    all_data = []\n",
        "\n",
        "    for f in tqdm(SELECTED_FILES, desc=f\"Processing {len(SELECTED_FILES)} files\"):\n",
        "        path = os.path.join(DATA_DIR, f)\n",
        "        data = read_filter_file(path)\n",
        "        all_data.append(data)\n",
        "\n",
        "    if len(all_data) == 0:\n",
        "        print(\"No data to combine!\")\n",
        "        return\n",
        "\n",
        "    combined = np.concatenate(all_data)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(combined)\n",
        "\n",
        "    # Aggregate by target_name\n",
        "    agg_df = df.groupby('target_name', as_index=False).agg({\n",
        "        'xco2':'median',\n",
        "        'latitude':'mean',\n",
        "        'longitude':'mean',\n",
        "        'operation_mode':'first',   # keep a representative value\n",
        "        'xco2_quality_flag':'first' # keep a representative value\n",
        "    })\n",
        "\n",
        "    # Save CSV\n",
        "    out_path = os.path.join(OUTPUT_DIR, output_csv)\n",
        "    agg_df.to_csv(out_path, index=False)\n",
        "    print(f\"Saved combined CSV: {out_path}\")\n"
      ],
      "metadata": {
        "id": "KJxFYZ_5A0jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After choosing number of files in the slider above, run this\n",
        "\n",
        "combine_files()"
      ],
      "metadata": {
        "id": "63F_N1tOBMKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **2. Data Exploration of NC4 File Variables**\n",
        "\n",
        "This is a tool to interactively select variables in a SINGLE nc4 file, allowing one to preview all nested variables in an nc4 file including hidden subfolders, and to plot them into a CSV for further processing. This is more for **data exploration** than data processing since individual csvs produced here still have large file sizes."
      ],
      "metadata": {
        "id": "n53fYInmzwai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from ipywidgets import interact, IntSlider, SelectMultiple\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Base folder containing .nc4 files (replace with your own google drive shortcut to D2D shared drive)\n",
        "DATA_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/2025-CO2-netcdfs\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Discover years and files\n",
        "files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".nc4\")]\n",
        "years = sorted(list({f.split('_')[2][:2] for f in files}))  # extract '24' from '240716'\n",
        "print(f\"Found {len(files)} total NC4 files.\")\n"
      ],
      "metadata": {
        "id": "br2lxwKiC7Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample files per year\n",
        "files_by_year = {}\n",
        "for f in files:\n",
        "    year = \"20\" + f.split('_')[2][:2]\n",
        "    files_by_year.setdefault(year, []).append(f)\n",
        "\n",
        "available_years = sorted(files_by_year.keys())\n",
        "print(\"Available years:\", available_years)\n",
        "\n",
        "# Let user choose interactively\n",
        "@interact(\n",
        "    year=available_years,\n",
        "    n_files=IntSlider(min=1, max=10, step=1, value=3, description='Files to process'),\n",
        ")\n",
        "def choose_year(year, n_files):\n",
        "    chosen = files_by_year[year][:n_files]\n",
        "    print(f\"Will process {len(chosen)} files from {year}:\")\n",
        "    for f in chosen:\n",
        "        print(\" -\", f)\n",
        "    globals()['SELECTED_FILES'] = chosen\n"
      ],
      "metadata": {
        "id": "if7Ul_mAGUyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recursively collect dataset paths in an HDF5 file\n",
        "def collect_datasets(h5file):\n",
        "    dataset_paths = []\n",
        "\n",
        "    def visitor(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset):\n",
        "            dataset_paths.append(name)\n",
        "    h5file.visititems(visitor)\n",
        "    return dataset_paths\n",
        "\n",
        "# First, pick a sample file to list variables\n",
        "sample_file = os.path.join(DATA_DIR, SELECTED_FILES[0]) # test 1 file\n",
        "# sample_file = os.path.join(DATA_DIR, files[0]) # all files\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "    all_datasets = collect_datasets(f)\n",
        "\n",
        "# Let user select variables interactively\n",
        "\n",
        "preselected_vars = [\n",
        "    'sounding_id',\n",
        "    'Sounding/operation_mode',\n",
        "    'xco2',\n",
        "    'xco2_quality_flag',\n",
        "    'latitude',\n",
        "    'longitude',\n",
        "    'Sounding/target_name'\n",
        "]\n",
        "\n",
        "@interact(\n",
        "    variables=SelectMultiple(\n",
        "        options=all_datasets,\n",
        "        value=[v for v in preselected_vars if v in all_datasets],\n",
        "        description='Variables',\n",
        "        layout={'width': 'max-content'},\n",
        "        rows=15\n",
        "    )\n",
        ")\n",
        "def choose_variables(variables):\n",
        "    print(\"Selected variables for CSV extraction:\")\n",
        "    for v in variables:\n",
        "        print(\" -\", v)\n",
        "    globals()['SELECTED_VARS'] = variables\n"
      ],
      "metadata": {
        "id": "y5XS1DN-jUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get time from sounding_id and filter functions for good quality SAMs\n",
        "\n",
        "def filter_and_extract_time(df):\n",
        "    \"\"\"\n",
        "    Filter the DataFrame for SAM/AM mode and good quality, and extract datetime from sounding_id.\n",
        "    \"\"\"\n",
        "    # Ensure sounding_id is string\n",
        "    df['sounding_id'] = df['sounding_id'].astype(str)\n",
        "\n",
        "    # Extract datetime from sounding_id (YYYYMMDDHHMM)\n",
        "    df['year'] = df['sounding_id'].str[:4].astype(int)\n",
        "    df['month'] = df['sounding_id'].str[4:6].astype(int)\n",
        "    df['day'] = df['sounding_id'].str[6:8].astype(int)\n",
        "    df['hour'] = df['sounding_id'].str[8:10].astype(int)\n",
        "    df['minute'] = df['sounding_id'].str[10:12].astype(int)\n",
        "    df['datetime'] = pd.to_datetime(df[['year','month','day','hour','minute']])\n",
        "\n",
        "    # Filter for SAM (AM) only\n",
        "    df = df[df['sounding_operation_mode'] == 'AM']\n",
        "\n",
        "    # Filter for good quality flag\n",
        "    df = df[df['xco2_quality_flag'] == 0]\n",
        "\n",
        "    # Drop intermediate columns\n",
        "    df = df.drop(columns=['year','month','day','hour','minute'])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Rm4K2Kh1ss4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV file extraction\n",
        "\n",
        "def process_nc4_file(local_path, variables): # all files\n",
        "    filename = os.path.basename(local_path)\n",
        "    csv_name = os.path.join(OUTPUT_DIR, filename.replace(\".nc4\", \".csv\"))\n",
        "\n",
        "    try:\n",
        "        with h5py.File(local_path, 'r') as f:\n",
        "            out_dict = {}\n",
        "            for var in variables:\n",
        "                # Direct access\n",
        "                if var in f:\n",
        "                    out_dict[var.replace('/', '_')] = f[var][...]\n",
        "                else:\n",
        "                    # Search for nested dataset ending with last component of var\n",
        "                    var_name = var.split('/')[-1]\n",
        "                    found = False\n",
        "                    def find_dataset(name, obj):\n",
        "                        nonlocal found\n",
        "                        if isinstance(obj, h5py.Dataset) and name.endswith(var_name):\n",
        "                            out_dict[name.replace('/', '_')] = obj[...]\n",
        "                            found = True\n",
        "                    f.visititems(find_dataset)\n",
        "                    if not found:\n",
        "                        print(f\"Warning: variable {var} not found in {filename}\")\n",
        "\n",
        "            # Map Sounding/operation_mode integers to strings if present\n",
        "            key_opmode = [k for k in out_dict.keys() if k.endswith('operation_mode')]\n",
        "            if key_opmode:\n",
        "                k = key_opmode[0]\n",
        "                mapping = {0: 'ND', 1: 'GL', 2: 'TG', 3: 'XS', 4: 'AM'}\n",
        "                out_dict[k] = [mapping.get(int(v), 'UNK') for v in out_dict[k]]\n",
        "\n",
        "            df = pd.DataFrame(out_dict)\n",
        "\n",
        "            # Filter for SAM mode (AM) and good quality, and extract datetime\n",
        "            if 'sounding_operation_mode' in df.columns and 'xco2_quality_flag' in df.columns:\n",
        "                df = df[(df['sounding_operation_mode'] == 'AM') & (df['xco2_quality_flag'] == 0)]\n",
        "            if 'sounding_id' in df.columns:\n",
        "                df['datetime'] = df['sounding_id'].astype(str).apply(\n",
        "                    lambda x: f\"20{x[:2]}-{x[2:4]}-{x[4:6]} {x[8:10]}:{x[10:12]}:00\"\n",
        "                )\n",
        "\n",
        "            df.to_csv(csv_name, index=False)\n",
        "            print(f\"Saved CSV: {csv_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed {local_path}: {e}\")\n"
      ],
      "metadata": {
        "id": "nQeUnj3VGiV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all():\n",
        "    for f in tqdm(SELECTED_FILES, desc=f\"Processing {len(SELECTED_FILES)} files\"):\n",
        "        local_path = os.path.join(DATA_DIR, f)\n",
        "        process_nc4_file(local_path, SELECTED_VARS)\n",
        "\n",
        "run_all()\n"
      ],
      "metadata": {
        "id": "1yXO9MT6Hky_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}