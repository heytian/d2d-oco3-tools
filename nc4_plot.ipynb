{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvkwbIRR/UAu2lFb2QRP82",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heytian/d2d-oco3-tools/blob/main/nc4_plot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from ipywidgets import interact, IntSlider, SelectMultiple\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Base folder containing .nc4 files (replace with your own google drive shortcut to D2D shared drive)\n",
        "DATA_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/2019-CO2-netcdfs\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Discover years and files\n",
        "files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".nc4\")]\n",
        "years = sorted(list({f.split('_')[2][:2] for f in files}))  # extract '24' from '240716'\n",
        "print(f\"Found {len(files)} total NC4 files.\")\n"
      ],
      "metadata": {
        "id": "br2lxwKiC7Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample files per year\n",
        "files_by_year = {}\n",
        "for f in files:\n",
        "    year = \"20\" + f.split('_')[2][:2]\n",
        "    files_by_year.setdefault(year, []).append(f)\n",
        "\n",
        "available_years = sorted(files_by_year.keys())\n",
        "print(\"Available years:\", available_years)\n",
        "\n",
        "# Let user choose interactively\n",
        "@interact(\n",
        "    year=available_years,\n",
        "    n_files=IntSlider(min=1, max=10, step=1, value=3, description='Files to process'),\n",
        ")\n",
        "def choose_year(year, n_files):\n",
        "    chosen = files_by_year[year][:n_files]\n",
        "    print(f\"Will process {len(chosen)} files from {year}:\")\n",
        "    for f in chosen:\n",
        "        print(\" -\", f)\n",
        "    globals()['SELECTED_FILES'] = chosen\n"
      ],
      "metadata": {
        "id": "if7Ul_mAGUyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recursively collect dataset paths in an HDF5 file\n",
        "def collect_datasets(h5file):\n",
        "    dataset_paths = []\n",
        "\n",
        "    def visitor(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset):\n",
        "            dataset_paths.append(name)\n",
        "    h5file.visititems(visitor)\n",
        "    return dataset_paths\n",
        "\n",
        "# First, pick a sample file to list variables\n",
        "sample_file = os.path.join(DATA_DIR, files[0])\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "    all_datasets = collect_datasets(f)\n",
        "\n",
        "# Let user select variables interactively\n",
        "\n",
        "preselected_vars = [\n",
        "    'Sounding/target_id',\n",
        "    'Sounding/operation_mode',\n",
        "    'xco2',\n",
        "    'xco2_quality_flag',\n",
        "    'latitude',\n",
        "    'longitude',\n",
        "    'time'\n",
        "]\n",
        "\n",
        "@interact(\n",
        "    variables=SelectMultiple(\n",
        "        options=all_datasets,\n",
        "        value=[v for v in preselected_vars if v in all_datasets],\n",
        "        description='Variables',\n",
        "        layout={'width': 'max-content'},\n",
        "        rows=15\n",
        "    )\n",
        ")\n",
        "def choose_variables(variables):\n",
        "    print(\"Selected variables for CSV extraction:\")\n",
        "    for v in variables:\n",
        "        print(\" -\", v)\n",
        "    globals()['SELECTED_VARS'] = variables\n"
      ],
      "metadata": {
        "id": "y5XS1DN-jUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV file extraction\n",
        "\n",
        "def process_nc4_file(local_path, variables):\n",
        "    filename = os.path.basename(local_path)\n",
        "    csv_name = os.path.join(OUTPUT_DIR, filename.replace(\".nc4\", \".csv\"))\n",
        "\n",
        "    try:\n",
        "        with h5py.File(local_path, 'r') as f:\n",
        "            out_dict = {}\n",
        "            for var in variables:\n",
        "                # Direct access\n",
        "                if var in f:\n",
        "                    out_dict[var.replace('/', '_')] = f[var][...]\n",
        "                else:\n",
        "                    # Search for nested dataset ending with last component of var\n",
        "                    var_name = var.split('/')[-1]\n",
        "                    found = False\n",
        "                    def find_dataset(name, obj):\n",
        "                        nonlocal found\n",
        "                        if isinstance(obj, h5py.Dataset) and name.endswith(var_name):\n",
        "                            out_dict[name.replace('/', '_')] = obj[...]\n",
        "                            found = True\n",
        "                    f.visititems(find_dataset)\n",
        "                    if not found:\n",
        "                        print(f\"Warning: variable {var} not found in {filename}\")\n",
        "\n",
        "            # Map Sounding/operation_mode integers to strings if present\n",
        "            key_opmode = [k for k in out_dict.keys() if k.endswith('operation_mode')]\n",
        "            if key_opmode:\n",
        "                k = key_opmode[0]\n",
        "                mapping = {0: 'ND', 1: 'GL', 2: 'TG', 3: 'XS', 4: 'AM'}\n",
        "                out_dict[k] = [mapping.get(int(v), 'UNK') for v in out_dict[k]]\n",
        "\n",
        "            df = pd.DataFrame(out_dict)\n",
        "            df.to_csv(csv_name, index=False)\n",
        "            print(f\"Saved CSV: {csv_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed {local_path}: {e}\")\n"
      ],
      "metadata": {
        "id": "nQeUnj3VGiV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all():\n",
        "    for f in tqdm(SELECTED_FILES, desc=f\"Processing {len(SELECTED_FILES)} files\"):\n",
        "        local_path = os.path.join(DATA_DIR, f)\n",
        "        process_nc4_file(local_path, SELECTED_VARS)\n",
        "\n",
        "run_all()\n"
      ],
      "metadata": {
        "id": "1yXO9MT6Hky_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}