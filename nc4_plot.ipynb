{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUYfQvxE5OgXvZfmkHqE5S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heytian/d2d-oco3-tools/blob/main/nc4_plot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from ipywidgets import interact, IntSlider, SelectMultiple\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Base folder containing .nc4 files (replace with your own google drive shortcut to D2D shared drive)\n",
        "DATA_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/2019-CO2-netcdfs\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shortcuts/DATA/output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Discover years and files\n",
        "files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".nc4\")]\n",
        "years = sorted(list({f.split('_')[2][:2] for f in files}))  # extract '24' from '240716'\n",
        "print(f\"Found {len(files)} total NC4 files.\")\n"
      ],
      "metadata": {
        "id": "br2lxwKiC7Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Data exploration - List the variables in each netcdf file, along with their subfolders\n",
        "\n",
        "# def print_hdf5_structure(name, obj):\n",
        "#     print(name)\n",
        "\n",
        "# with h5py.File(sample_file, \"r\") as f:\n",
        "#     f.visititems(print_hdf5_structure)"
      ],
      "metadata": {
        "id": "o-jUABoBhfvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample files per year\n",
        "files_by_year = {}\n",
        "for f in files:\n",
        "    year = \"20\" + f.split('_')[2][:2]\n",
        "    files_by_year.setdefault(year, []).append(f)\n",
        "\n",
        "available_years = sorted(files_by_year.keys())\n",
        "print(\"Available years:\", available_years)\n",
        "\n",
        "# Let user choose interactively\n",
        "@interact(\n",
        "    year=available_years,\n",
        "    n_files=IntSlider(min=1, max=10, step=1, value=3, description='Files to process'),\n",
        ")\n",
        "def choose_year(year, n_files):\n",
        "    chosen = files_by_year[year][:n_files]\n",
        "    print(f\"Will process {len(chosen)} files from {year}:\")\n",
        "    for f in chosen:\n",
        "        print(\" -\", f)\n",
        "    globals()['SELECTED_FILES'] = chosen\n"
      ],
      "metadata": {
        "id": "if7Ul_mAGUyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recursively collect dataset paths in an HDF5 file\n",
        "def collect_datasets(h5file):\n",
        "    dataset_paths = []\n",
        "\n",
        "    def visitor(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset):\n",
        "            dataset_paths.append(name)\n",
        "    h5file.visititems(visitor)\n",
        "    return dataset_paths\n",
        "\n",
        "# First, pick a sample file to list variables\n",
        "sample_file = os.path.join(DATA_DIR, files[0])\n",
        "with h5py.File(sample_file, 'r') as f:\n",
        "    all_datasets = collect_datasets(f)\n",
        "\n",
        "# Let user select variables interactively\n",
        "\n",
        "preselected_vars = [\n",
        "    'Sounding/target_id',\n",
        "    'Sounding/operation_mode',\n",
        "    'xco2',\n",
        "    'xco2_quality_flag',\n",
        "    'latitude',\n",
        "    'longitude',\n",
        "    'time'\n",
        "]\n",
        "\n",
        "@interact(\n",
        "    variables=SelectMultiple(\n",
        "        options=all_datasets,\n",
        "        value=[v for v in preselected_vars if v in all_datasets],\n",
        "        description='Variables',\n",
        "        layout={'width': 'max-content'},\n",
        "        rows=15\n",
        "    )\n",
        ")\n",
        "def choose_variables(variables):\n",
        "    print(\"Selected variables for CSV extraction:\")\n",
        "    for v in variables:\n",
        "        print(\" -\", v)\n",
        "    globals()['SELECTED_VARS'] = variables\n"
      ],
      "metadata": {
        "id": "y5XS1DN-jUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't choose \"date\" as one of the variables, just \"time\" will show date time etc. \"Date\" weirdly breaks a day down into 7+ rows i.e. year, month, day, time - each becomes one row."
      ],
      "metadata": {
        "id": "BNId7mo1Iz97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Let user preview variables in the first file\n",
        "# sample_file = os.path.join(DATA_DIR, files[0])\n",
        "# ds = xr.open_dataset(sample_file)\n",
        "# vars_list = list(ds.variables)\n",
        "# print(f\"Variables found in sample file ({len(vars_list)}):\")\n",
        "# print(vars_list[:20])  # show a subset\n",
        "\n",
        "# @interact\n",
        "# def choose_vars(\n",
        "#     csv_vars=SelectMultiple(options=vars_list, value=(\"xco2\", \"latitude\", \"longitude\", \"time\"), description=\"CSV vars\"),\n",
        "#     geo_var=SelectMultiple(options=vars_list, value=(\"xco2\",), description=\"Geo var\")\n",
        "# ):\n",
        "#     globals()['CSV_VARS'] = list(csv_vars)\n",
        "#     globals()['GEO_VARS'] = list(geo_var)[0]\n",
        "#     print(f\"Selected CSV vars: {CSV_VARS}\")\n",
        "#     print(f\"Selected Geo var: {GEO_VARS}\")\n"
      ],
      "metadata": {
        "id": "j8tDzzN5GdUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV file extraction\n",
        "\n",
        "def process_nc4_file(local_path, variables):\n",
        "    filename = os.path.basename(local_path)\n",
        "    csv_name = os.path.join(OUTPUT_DIR, filename.replace(\".nc4\", \".csv\"))\n",
        "\n",
        "    try:\n",
        "        with h5py.File(local_path, 'r') as f:\n",
        "            out_dict = {}\n",
        "            for var in variables:\n",
        "                # Direct access\n",
        "                if var in f:\n",
        "                    out_dict[var.replace('/', '_')] = f[var][...]\n",
        "                else:\n",
        "                    # Search for nested dataset ending with last component of var\n",
        "                    var_name = var.split('/')[-1]\n",
        "                    found = False\n",
        "                    def find_dataset(name, obj):\n",
        "                        nonlocal found\n",
        "                        if isinstance(obj, h5py.Dataset) and name.endswith(var_name):\n",
        "                            out_dict[name.replace('/', '_')] = obj[...]\n",
        "                            found = True\n",
        "                    f.visititems(find_dataset)\n",
        "                    if not found:\n",
        "                        print(f\"Warning: variable {var} not found in {filename}\")\n",
        "\n",
        "            # Map Sounding/operation_mode integers to strings if present\n",
        "            key_opmode = [k for k in out_dict.keys() if k.endswith('operation_mode')]\n",
        "            if key_opmode:\n",
        "                k = key_opmode[0]\n",
        "                mapping = {0: 'ND', 1: 'GL', 2: 'TG', 3: 'XS', 4: 'AM'}\n",
        "                out_dict[k] = [mapping.get(int(v), 'UNK') for v in out_dict[k]]\n",
        "\n",
        "            df = pd.DataFrame(out_dict)\n",
        "            df.to_csv(csv_name, index=False)\n",
        "            print(f\"Saved CSV: {csv_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed {local_path}: {e}\")\n"
      ],
      "metadata": {
        "id": "nQeUnj3VGiV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all():\n",
        "    for f in tqdm(SELECTED_FILES, desc=f\"Processing {len(SELECTED_FILES)} files\"):\n",
        "        local_path = os.path.join(DATA_DIR, f)\n",
        "        process_nc4_file(local_path, SELECTED_VARS)\n",
        "\n",
        "run_all()\n"
      ],
      "metadata": {
        "id": "1yXO9MT6Hky_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}